{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     3644\n",
       "8     3644\n",
       "7     3644\n",
       "6     3644\n",
       "5     3644\n",
       "4     3644\n",
       "3     3644\n",
       "2     3644\n",
       "1     3644\n",
       "10    3553\n",
       "12    3523\n",
       "11    3523\n",
       "Name: Month, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"Local_Area_Unemployment_Statistics__LAUS_1.csv\", thousands=',', low_memory=False) \n",
    "data.drop_duplicates(keep = False, inplace = True)\n",
    "data = data[data[\"Unemployment Rate\"] != \"#DIV/0!\"]\n",
    "data = data[data[\"Labor Force\"] > 0]\n",
    "counts = data[\"Area Name\"].value_counts()\n",
    "data = data[~data[\"Area Name\"].isin(counts[counts < 120].index)]\n",
    "data = data[data[\"Status (Preliminary / Final)\"] != \"Preliminary\"]\n",
    "data = data.drop(['Area Type', 'Date', 'Status (Preliminary / Final)', 'Employment', \"Unemployment\"], axis=1)\n",
    "dic_month = {\"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \"May\": 5, \"June\": 6, \"July\": 7,\n",
    "            \"August\": 8, \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12}\n",
    "data = data.replace(dic_month)\n",
    "data[\"Month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Unemployment Rate\"] = data[\"Unemployment Rate\"].astype(float)\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(data[\"Unemployment Rate\"], kde=False, rug=True);\n",
    "plt.savefig('Unemployment rate diagram.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.array(data['Unemployment Rate'].values.tolist())\n",
    "data['Unemployment Rate'] = np.where(a > 0.1, 2, \n",
    "         (np.where(a < 0.05, 0, 1))).tolist() #Employment rate>0.1, high(2); 0.05<=<=0.1(1), medium; 0<0.05, low(0).\n",
    "data[\"Unemployment Rate\"].value_counts()\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(data[\"Unemployment Rate\"], kde=False, rug=True);\n",
    "plt.savefig('Three levels.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_rule = data[:]\n",
    "a = np.array(data['Unemployment Rate'].values.tolist())\n",
    "data_rule['Unemployment Rate'] = np.where(a == 2, 1, 0).tolist() #Employment rate>0.1, high(1); 0<=0.1, low&medium(0).\n",
    "data_rule[\"Unemployment Rate\"].value_counts()\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(data_rule[\"Unemployment Rate\"], kde=False, rug=True);\n",
    "plt.savefig('Two levels.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Seasonally Adjusted (Y/N)</th>\n",
       "      <th>Labor Force</th>\n",
       "      <th>Unemployment Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>1976</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>9734600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>California</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>10132600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>10675100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>11130900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>11479800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area Name  Year  Month Seasonally Adjusted (Y/N)  Labor Force  \\\n",
       "0  California  1976      1                         Y      9734600   \n",
       "1  California  1977      1                         Y     10132600   \n",
       "2  California  1978      1                         Y     10675100   \n",
       "3  California  1979      1                         Y     11130900   \n",
       "4  California  1980      1                         Y     11479800   \n",
       "\n",
       "   Unemployment Rate  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Area Name_0', 'Area Name_1', 'Area Name_2', 'Area Name_3', 'Area Name_4', 'Area Name_5', 'Area Name_6', 'Area Name_7', 'Year', 'Month', 'Labor Force', 'Seasonally Adjusted (Y/N)_N', 'Seasonally Adjusted (Y/N)_Y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Name_0</th>\n",
       "      <th>Area Name_1</th>\n",
       "      <th>Area Name_2</th>\n",
       "      <th>Area Name_3</th>\n",
       "      <th>Area Name_4</th>\n",
       "      <th>Area Name_5</th>\n",
       "      <th>Area Name_6</th>\n",
       "      <th>Area Name_7</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Labor Force</th>\n",
       "      <th>Seasonally Adjusted (Y/N)_N</th>\n",
       "      <th>Seasonally Adjusted (Y/N)_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1976</td>\n",
       "      <td>1</td>\n",
       "      <td>9734600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>10132600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>10675100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>11130900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>11479800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area Name_0  Area Name_1  Area Name_2  Area Name_3  Area Name_4  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Area Name_5  Area Name_6  Area Name_7  Year  Month  Labor Force  \\\n",
       "0            0            0            1  1976      1      9734600   \n",
       "1            0            0            1  1977      1     10132600   \n",
       "2            0            0            1  1978      1     10675100   \n",
       "3            0            0            1  1979      1     11130900   \n",
       "4            0            0            1  1980      1     11479800   \n",
       "\n",
       "   Seasonally Adjusted (Y/N)_N  Seasonally Adjusted (Y/N)_Y  \n",
       "0                            0                            1  \n",
       "1                            0                            1  \n",
       "2                            0                            1  \n",
       "3                            0                            1  \n",
       "4                            0                            1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=[\"Area Name\"])\n",
    "y = data[\"Unemployment Rate\"]\n",
    "y_rule = data_rule[\"Unemployment Rate\"]\n",
    "X = data.drop(\"Unemployment Rate\", axis=1)\n",
    "encoder.fit(X, y)\n",
    "X_enc = encoder.transform(X)\n",
    "X_enc = pd.get_dummies(X_enc, columns=[\"Seasonally Adjusted (Y/N)\"])\n",
    "\n",
    "X_enc = pd.DataFrame(X_enc)\n",
    "feature_names = list(X_enc.columns.values)\n",
    "print(feature_names)\n",
    "\n",
    "X_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Name_0</th>\n",
       "      <th>Area Name_1</th>\n",
       "      <th>Area Name_2</th>\n",
       "      <th>Area Name_3</th>\n",
       "      <th>Area Name_4</th>\n",
       "      <th>Area Name_5</th>\n",
       "      <th>Area Name_6</th>\n",
       "      <th>Area Name_7</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Labor Force</th>\n",
       "      <th>Seasonally Adjusted (Y/N)_N</th>\n",
       "      <th>Seasonally Adjusted (Y/N)_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.953488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.034123</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.906977</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.089491</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.860465</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.136011</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.813953</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.171620</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area Name_0  Area Name_1  Area Name_2  Area Name_3  Area Name_4  \\\n",
       "0         -1.0         -1.0         -1.0         -1.0         -1.0   \n",
       "1         -1.0         -1.0         -1.0         -1.0         -1.0   \n",
       "2         -1.0         -1.0         -1.0         -1.0         -1.0   \n",
       "3         -1.0         -1.0         -1.0         -1.0         -1.0   \n",
       "4         -1.0         -1.0         -1.0         -1.0         -1.0   \n",
       "\n",
       "   Area Name_5  Area Name_6  Area Name_7      Year  Month  Labor Force  \\\n",
       "0         -1.0         -1.0          1.0 -1.000000   -1.0    -0.006497   \n",
       "1         -1.0         -1.0          1.0 -0.953488   -1.0     0.034123   \n",
       "2         -1.0         -1.0          1.0 -0.906977   -1.0     0.089491   \n",
       "3         -1.0         -1.0          1.0 -0.860465   -1.0     0.136011   \n",
       "4         -1.0         -1.0          1.0 -0.813953   -1.0     0.171620   \n",
       "\n",
       "   Seasonally Adjusted (Y/N)_N  Seasonally Adjusted (Y/N)_Y  \n",
       "0                         -1.0                          1.0  \n",
       "1                         -1.0                          1.0  \n",
       "2                         -1.0                          1.0  \n",
       "3                         -1.0                          1.0  \n",
       "4                         -1.0                          1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "data_scale = min_max_scaler.fit_transform(X_enc)\n",
    "X_enc = pd.DataFrame(data_scale)\n",
    "\n",
    "feature_dict = {}\n",
    "for i in range(len(feature_names)):\n",
    "    feature_dict[i] = feature_names[i]\n",
    "X_enc = X_enc.rename(columns=feature_dict)\n",
    "X_enc.head()\n",
    "\n",
    "# Features: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '2': 20381\n",
      "After OverSampling, counts of label '1': 20381\n",
      "After OverSampling, counts of label '0': 20381\n",
      "-------------------------------------------------------------\n",
      "After UnderSampling, counts of label '2': 9180\n",
      "After UnderSampling, counts of label '1': 9180\n",
      "After UnderSampling, counts of label '0': 9180\n",
      "-------------------------------------------------------------\n",
      "After BalancedSampling, counts of label '2': 15567\n",
      "After BalancedSampling, counts of label '1': 9324\n",
      "After BalancedSampling, counts of label '0': 15536\n",
      "-------------------------------------------------------------\n",
      "After OverSampling, counts of label '1': 29561\n",
      "After OverSampling, counts of label '0': 29561\n",
      "-------------------------------------------------------------\n",
      "After UnderSampling, counts of label '1': 13834\n",
      "After UnderSampling, counts of label '0': 13834\n",
      "-------------------------------------------------------------\n",
      "After BalancedSampling, counts of label '1': 25213\n",
      "After BalancedSampling, counts of label '0': 23596\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=2)\n",
    "X_over, y_over = sm.fit_sample(X_enc, y)\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_over==2)))\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_over==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_over==0)))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=2)\n",
    "X_und, y_und = rus.fit_resample(X_enc, y)\n",
    "print(\"After UnderSampling, counts of label '2': {}\".format(sum(y_und==2)))\n",
    "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_und==1)))\n",
    "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_und==0)))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "sme = SMOTEENN(random_state=42)\n",
    "X_bal, y_bal = sme.fit_resample(X_enc, y)\n",
    "print(\"After BalancedSampling, counts of label '2': {}\".format(sum(y_bal==2)))\n",
    "print(\"After BalancedSampling, counts of label '1': {}\".format(sum(y_bal==1)))\n",
    "print(\"After BalancedSampling, counts of label '0': {}\".format(sum(y_bal==0)))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "X_over_rule, y_over_rule = sm.fit_sample(X_enc, y_rule)\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_over_rule==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_over_rule==0)))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "X_und_rule, y_und_rule = rus.fit_resample(X_enc, y_rule)\n",
    "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_und_rule==1)))\n",
    "print(\"After UnderSampling, counts of label '0': {}\".format(sum(y_und_rule==0)))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "X_bal_rule, y_bal_rule = sme.fit_resample(X_enc, y_rule)\n",
    "print(\"After BalancedSampling, counts of label '1': {}\".format(sum(y_bal_rule==1)))\n",
    "print(\"After BalancedSampling, counts of label '0': {}\".format(sum(y_bal_rule==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAfter Over Sampling: ---------------------------------------------------------------------------\n",
      "\u001b[0;0mLinear-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.420   | 0.403  | 0.852  | 0.547 | 0.448  | 0.128  | 0.198 | 0.468  | 0.281  | 0.351 |    0.365     |\n",
      "|     2     |  0.372   | 0.497  | 0.428  | 0.460 | 0.323  | 0.667  | 0.435 | 0.310  | 0.022  | 0.041 |    0.312     |\n",
      "|     3     |  0.357   | 0.514  | 0.334  | 0.405 | 0.287  | 0.377  | 0.326 | 0.346  | 0.359  | 0.352 |    0.361     |\n",
      "|     4     |  0.268   | 0.338  | 0.205  | 0.255 | 0.236  | 0.148  | 0.182 | 0.256  | 0.452  | 0.326 |    0.255     |\n",
      "|     5     |  0.350   | 0.345  | 0.234  | 0.279 | 0.334  | 0.236  | 0.277 | 0.359  | 0.580  | 0.443 |    0.333     |\n",
      "|     6     |  0.323   | 0.142  | 0.091  | 0.111 | 0.335  | 0.458  | 0.387 | 0.423  | 0.421  | 0.422 |    0.307     |\n",
      "|     7     |  0.380   | 0.425  | 0.540  | 0.476 | 0.264  | 0.149  | 0.190 | 0.387  | 0.452  | 0.417 |    0.361     |\n",
      "|     8     |  0.427   | 0.429  | 0.671  | 0.523 | 0.544  | 0.091  | 0.156 | 0.409  | 0.519  | 0.457 |    0.379     |\n",
      "|     9     |  0.297   | 0.438  | 0.542  | 0.484 | 0.015  | 0.010  | 0.012 | 0.304  | 0.339  | 0.321 |    0.272     |\n",
      "|     10    |  0.394   | 0.489  | 0.570  | 0.527 | 0.307  | 0.232  | 0.264 | 0.353  | 0.380  | 0.366 |    0.386     |\n",
      "|  Average  |  0.359   | 0.402  | 0.447  | 0.407 | 0.309  | 0.250  | 0.243 | 0.362  | 0.380  | 0.350 |    0.333     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mLinear-based Model 2:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.432   | 0.406  | 0.806  | 0.540 | 0.515  | 0.091  | 0.154 | 0.474  | 0.398  | 0.433 |    0.376     |\n",
      "|     2     |  0.430   | 0.440  | 0.681  | 0.534 | 0.397  | 0.135  | 0.202 | 0.428  | 0.475  | 0.450 |    0.396     |\n",
      "|     3     |  0.386   | 0.475  | 0.590  | 0.526 | 0.254  | 0.161  | 0.197 | 0.362  | 0.406  | 0.383 |    0.369     |\n",
      "|     4     |  0.356   | 0.376  | 0.452  | 0.410 | 0.316  | 0.185  | 0.234 | 0.357  | 0.432  | 0.391 |    0.345     |\n",
      "|     5     |  0.302   | 0.231  | 0.163  | 0.191 | 0.265  | 0.225  | 0.243 | 0.358  | 0.517  | 0.423 |    0.286     |\n",
      "|     6     |  0.332   | 0.262  | 0.280  | 0.271 | 0.278  | 0.169  | 0.210 | 0.414  | 0.548  | 0.472 |    0.318     |\n",
      "|     7     |  0.327   | 0.303  | 0.300  | 0.302 | 0.221  | 0.128  | 0.162 | 0.387  | 0.555  | 0.456 |    0.306     |\n",
      "|     8     |  0.439   | 0.479  | 0.579  | 0.524 | 0.423  | 0.173  | 0.246 | 0.408  | 0.564  | 0.474 |    0.414     |\n",
      "|     9     |  0.343   | 0.442  | 0.525  | 0.480 | 0.014  | 0.006  | 0.008 | 0.360  | 0.499  | 0.418 |    0.302     |\n",
      "|     10    |  0.351   | 0.444  | 0.538  | 0.486 | 0.024  | 0.010  | 0.014 | 0.365  | 0.507  | 0.425 |    0.308     |\n",
      "|  Average  |  0.370   | 0.386  | 0.491  | 0.426 | 0.271  | 0.128  | 0.167 | 0.391  | 0.490  | 0.432 |    0.342     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mTree-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.828   | 0.818  | 0.940  | 0.874 | 0.832  | 0.642  | 0.725 | 0.837  | 0.903  | 0.869 |    0.823     |\n",
      "|     2     |  0.842   | 0.859  | 0.926  | 0.891 | 0.806  | 0.710  | 0.755 | 0.855  | 0.890  | 0.872 |    0.839     |\n",
      "|     3     |  0.836   | 0.847  | 0.927  | 0.885 | 0.789  | 0.709  | 0.747 | 0.865  | 0.871  | 0.868 |    0.833     |\n",
      "|     4     |  0.819   | 0.901  | 0.751  | 0.819 | 0.711  | 0.784  | 0.746 | 0.867  | 0.922  | 0.894 |    0.819     |\n",
      "|     5     |  0.823   | 0.844  | 0.738  | 0.787 | 0.729  | 0.763  | 0.745 | 0.899  | 0.970  | 0.933 |    0.822     |\n",
      "|     6     |  0.890   | 0.879  | 0.928  | 0.903 | 0.892  | 0.768  | 0.825 | 0.900  | 0.974  | 0.936 |    0.888     |\n",
      "|     7     |  0.880   | 0.868  | 0.948  | 0.906 | 0.900  | 0.725  | 0.803 | 0.878  | 0.967  | 0.920 |    0.877     |\n",
      "|     8     |  0.873   | 0.837  | 0.973  | 0.900 | 0.928  | 0.681  | 0.785 | 0.875  | 0.966  | 0.918 |    0.868     |\n",
      "|     9     |  0.937   | 0.940  | 0.982  | 0.961 | 0.950  | 0.862  | 0.904 | 0.922  | 0.966  | 0.943 |    0.936     |\n",
      "|     10    |  0.952   | 0.962  | 0.977  | 0.970 | 0.950  | 0.914  | 0.932 | 0.943  | 0.965  | 0.954 |    0.952     |\n",
      "|  Average  |  0.868   | 0.875  | 0.909  | 0.890 | 0.849  | 0.756  | 0.797 | 0.884  | 0.939  | 0.911 |    0.866     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mBagging-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.859   | 0.868  | 0.951  | 0.907 | 0.880  | 0.677  | 0.765 | 0.837  | 0.949  | 0.890 |    0.854     |\n",
      "|     2     |  0.861   | 0.908  | 0.904  | 0.906 | 0.817  | 0.765  | 0.790 | 0.857  | 0.915  | 0.885 |    0.860     |\n",
      "|     3     |  0.849   | 0.862  | 0.930  | 0.895 | 0.805  | 0.733  | 0.767 | 0.874  | 0.883  | 0.878 |    0.847     |\n",
      "|     4     |  0.804   | 0.890  | 0.754  | 0.817 | 0.692  | 0.759  | 0.724 | 0.852  | 0.900  | 0.875 |    0.805     |\n",
      "|     5     |  0.831   | 0.880  | 0.709  | 0.785 | 0.719  | 0.815  | 0.764 | 0.914  | 0.970  | 0.941 |    0.830     |\n",
      "|     6     |  0.877   | 0.859  | 0.920  | 0.888 | 0.879  | 0.736  | 0.801 | 0.894  | 0.976  | 0.934 |    0.874     |\n",
      "|     7     |  0.847   | 0.840  | 0.947  | 0.890 | 0.888  | 0.621  | 0.731 | 0.830  | 0.974  | 0.896 |    0.839     |\n",
      "|     8     |  0.865   | 0.858  | 0.979  | 0.915 | 0.932  | 0.643  | 0.761 | 0.831  | 0.972  | 0.896 |    0.857     |\n",
      "|     9     |  0.951   | 0.947  | 0.986  | 0.966 | 0.959  | 0.894  | 0.925 | 0.946  | 0.973  | 0.959 |    0.950     |\n",
      "|     10    |  0.960   | 0.974  | 0.985  | 0.980 | 0.956  | 0.926  | 0.941 | 0.948  | 0.968  | 0.958 |    0.959     |\n",
      "|  Average  |  0.870   | 0.889  | 0.906  | 0.895 | 0.853  | 0.757  | 0.797 | 0.878  | 0.948  | 0.911 |    0.868     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mBoosting-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.804   | 0.800  | 0.923  | 0.857 | 0.810  | 0.571  | 0.670 | 0.805  | 0.918  | 0.858 |    0.795     |\n",
      "|     2     |  0.815   | 0.854  | 0.919  | 0.885 | 0.776  | 0.644  | 0.704 | 0.807  | 0.882  | 0.843 |    0.811     |\n",
      "|     3     |  0.819   | 0.848  | 0.921  | 0.883 | 0.773  | 0.675  | 0.720 | 0.828  | 0.862  | 0.845 |    0.816     |\n",
      "|     4     |  0.761   | 0.827  | 0.718  | 0.769 | 0.636  | 0.690  | 0.662 | 0.837  | 0.876  | 0.856 |    0.762     |\n",
      "|     5     |  0.807   | 0.863  | 0.663  | 0.750 | 0.685  | 0.795  | 0.736 | 0.898  | 0.962  | 0.929 |    0.805     |\n",
      "|     6     |  0.873   | 0.853  | 0.934  | 0.892 | 0.889  | 0.714  | 0.792 | 0.882  | 0.972  | 0.924 |    0.869     |\n",
      "|     7     |  0.822   | 0.821  | 0.939  | 0.876 | 0.870  | 0.555  | 0.678 | 0.798  | 0.974  | 0.877 |    0.810     |\n",
      "|     8     |  0.856   | 0.831  | 0.971  | 0.895 | 0.919  | 0.632  | 0.748 | 0.844  | 0.965  | 0.900 |    0.848     |\n",
      "|     9     |  0.927   | 0.914  | 0.977  | 0.944 | 0.943  | 0.839  | 0.888 | 0.926  | 0.964  | 0.945 |    0.926     |\n",
      "|     10    |  0.941   | 0.967  | 0.974  | 0.971 | 0.943  | 0.886  | 0.913 | 0.915  | 0.963  | 0.938 |    0.941     |\n",
      "|  Average  |  0.843   | 0.858  | 0.894  | 0.872 | 0.824  | 0.700  | 0.751 | 0.854  | 0.934  | 0.892 |    0.838     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mDistance-based Model: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.732   | 0.772  | 0.969  | 0.860 | 0.754  | 0.329  | 0.458 | 0.686  | 0.898  | 0.778 |    0.698     |\n",
      "|     2     |  0.751   | 0.856  | 0.954  | 0.903 | 0.714  | 0.442  | 0.546 | 0.677  | 0.858  | 0.757 |    0.735     |\n",
      "|     3     |  0.706   | 0.812  | 0.870  | 0.840 | 0.619  | 0.390  | 0.479 | 0.661  | 0.859  | 0.747 |    0.689     |\n",
      "|     4     |  0.671   | 0.765  | 0.720  | 0.742 | 0.517  | 0.422  | 0.465 | 0.700  | 0.869  | 0.776 |    0.661     |\n",
      "|     5     |  0.657   | 0.703  | 0.720  | 0.711 | 0.486  | 0.345  | 0.404 | 0.715  | 0.904  | 0.799 |    0.638     |\n",
      "|     6     |  0.713   | 0.752  | 0.787  | 0.769 | 0.607  | 0.405  | 0.486 | 0.737  | 0.947  | 0.829 |    0.694     |\n",
      "|     7     |  0.697   | 0.727  | 0.814  | 0.768 | 0.589  | 0.333  | 0.425 | 0.718  | 0.945  | 0.816 |    0.670     |\n",
      "|     8     |  0.753   | 0.768  | 0.970  | 0.857 | 0.806  | 0.343  | 0.482 | 0.722  | 0.947  | 0.819 |    0.719     |\n",
      "|     9     |  0.705   | 0.737  | 0.974  | 0.839 | 0.717  | 0.194  | 0.305 | 0.672  | 0.947  | 0.786 |    0.644     |\n",
      "|     10    |  0.680   | 0.709  | 0.969  | 0.819 | 0.605  | 0.126  | 0.209 | 0.664  | 0.946  | 0.781 |    0.603     |\n",
      "|  Average  |  0.707   | 0.760  | 0.875  | 0.811 | 0.641  | 0.333  | 0.426 | 0.695  | 0.912  | 0.789 |    0.675     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mNaive Bayes Model: \n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.418   | 0.375  | 0.937  | 0.535 | 0.642  | 0.117  | 0.198 | 0.629  | 0.200  | 0.304 |    0.345     |\n",
      "|     2     |  0.421   | 0.383  | 0.866  | 0.531 | 0.640  | 0.122  | 0.205 | 0.503  | 0.275  | 0.355 |    0.364     |\n",
      "|     3     |  0.389   | 0.376  | 0.791  | 0.510 | 0.462  | 0.096  | 0.159 | 0.406  | 0.280  | 0.331 |    0.333     |\n",
      "|     4     |  0.299   | 0.336  | 0.569  | 0.422 | 0.329  | 0.095  | 0.147 | 0.230  | 0.235  | 0.232 |    0.267     |\n",
      "|     5     |  0.311   | 0.306  | 0.440  | 0.361 | 0.370  | 0.088  | 0.142 | 0.306  | 0.406  | 0.349 |    0.284     |\n",
      "|     6     |  0.184   | 0.060  | 0.089  | 0.072 | 0.235  | 0.104  | 0.144 | 0.333  | 0.359  | 0.345 |    0.187     |\n",
      "|     7     |  0.207   | 0.098  | 0.148  | 0.118 | 0.231  | 0.095  | 0.135 | 0.351  | 0.379  | 0.365 |    0.206     |\n",
      "|     8     |  0.426   | 0.415  | 0.739  | 0.532 | 0.522  | 0.076  | 0.133 | 0.432  | 0.464  | 0.448 |    0.371     |\n",
      "|     9     |  0.363   | 0.491  | 0.664  | 0.565 | 0.000  | 0.000  | 0.000 | 0.308  | 0.425  | 0.357 |    0.307     |\n",
      "|     10    |  0.381   | 0.529  | 0.703  | 0.604 | 0.000  | 0.000  | 0.000 | 0.306  | 0.441  | 0.361 |    0.322     |\n",
      "|  Average  |  0.340   | 0.337  | 0.595  | 0.425 | 0.343  | 0.079  | 0.126 | 0.380  | 0.346  | 0.345 |    0.299     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mRule-based Model: lables are only high unemployment rate(1) and not high unemployment rate(0)\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "|     id    | accuracy | precision | recall | f1 score |\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "|     1     |  0.586   |   0.754   | 0.256  |  0.382   |\n",
      "|     2     |  0.707   |   0.919   | 0.453  |  0.607   |\n",
      "|     3     |  0.661   |   0.759   | 0.470  |  0.581   |\n",
      "|     4     |  0.666   |   0.861   | 0.396  |  0.543   |\n",
      "|     5     |  0.648   |   0.802   | 0.394  |  0.528   |\n",
      "|     6     |  0.673   |   0.856   | 0.416  |  0.560   |\n",
      "|     7     |  0.638   |   0.728   | 0.440  |  0.548   |\n",
      "|     8     |  0.660   |   0.812   | 0.415  |  0.550   |\n",
      "|     9     |  0.662   |   0.787   | 0.443  |  0.567   |\n",
      "|     10    |  0.669   |   0.826   | 0.428  |  0.564   |\n",
      "|  Average  |  0.657   |   0.810   | 0.411  |  0.543   |\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "Instances are often misclassified:  93\n",
      "\u001b[1mAfter Under Sampling: ---------------------------------------------------------------------------\n",
      "\u001b[0;0mLinear-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.342   | 0.359  | 0.756  | 0.487 | 0.488  | 0.111  | 0.181 | 0.237  | 0.158  | 0.190 |    0.286     |\n",
      "|     2     |  0.332   | 0.338  | 0.637  | 0.441 | 0.468  | 0.197  | 0.277 | 0.235  | 0.162  | 0.192 |    0.304     |\n",
      "|     3     |  0.377   | 0.375  | 0.611  | 0.465 | 0.408  | 0.151  | 0.221 | 0.369  | 0.368  | 0.369 |    0.351     |\n",
      "|     4     |  0.391   | 0.430  | 0.380  | 0.403 | 0.342  | 0.448  | 0.388 | 0.429  | 0.346  | 0.383 |    0.392     |\n",
      "|     5     |  0.377   | 0.359  | 0.696  | 0.473 | 0.430  | 0.178  | 0.251 | 0.398  | 0.257  | 0.312 |    0.346     |\n",
      "|     6     |  0.370   | 0.478  | 0.422  | 0.448 | 0.322  | 0.447  | 0.374 | 0.329  | 0.241  | 0.278 |    0.367     |\n",
      "|     7     |  0.320   | 0.550  | 0.407  | 0.468 | 0.278  | 0.473  | 0.350 | 0.145  | 0.081  | 0.104 |    0.307     |\n",
      "|     8     |  0.341   | 0.475  | 0.275  | 0.348 | 0.319  | 0.439  | 0.370 | 0.296  | 0.309  | 0.302 |    0.340     |\n",
      "|     9     |  0.294   | 0.390  | 0.535  | 0.451 | 0.233  | 0.098  | 0.138 | 0.207  | 0.249  | 0.226 |    0.272     |\n",
      "|     10    |  0.380   | 0.396  | 0.524  | 0.451 | 0.401  | 0.325  | 0.359 | 0.335  | 0.291  | 0.312 |    0.374     |\n",
      "|  Average  |  0.352   | 0.415  | 0.524  | 0.444 | 0.369  | 0.287  | 0.291 | 0.298  | 0.246  | 0.267 |    0.334     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mLinear-based Model 2:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.320   | 0.360  | 0.608  | 0.452 | 0.421  | 0.156  | 0.227 | 0.207  | 0.195  | 0.201 |    0.293     |\n",
      "|     2     |  0.363   | 0.385  | 0.594  | 0.467 | 0.399  | 0.185  | 0.253 | 0.312  | 0.309  | 0.311 |    0.343     |\n",
      "|     3     |  0.400   | 0.415  | 0.586  | 0.486 | 0.384  | 0.185  | 0.250 | 0.387  | 0.428  | 0.406 |    0.381     |\n",
      "|     4     |  0.433   | 0.445  | 0.617  | 0.517 | 0.406  | 0.185  | 0.254 | 0.429  | 0.497  | 0.461 |    0.411     |\n",
      "|     5     |  0.393   | 0.437  | 0.573  | 0.496 | 0.333  | 0.228  | 0.271 | 0.376  | 0.378  | 0.377 |    0.381     |\n",
      "|     6     |  0.412   | 0.479  | 0.558  | 0.515 | 0.329  | 0.234  | 0.274 | 0.396  | 0.444  | 0.419 |    0.403     |\n",
      "|     7     |  0.337   | 0.488  | 0.542  | 0.514 | 0.247  | 0.239  | 0.243 | 0.247  | 0.229  | 0.238 |    0.332     |\n",
      "|     8     |  0.414   | 0.498  | 0.588  | 0.539 | 0.317  | 0.225  | 0.264 | 0.386  | 0.427  | 0.405 |    0.403     |\n",
      "|     9     |  0.372   | 0.389  | 0.603  | 0.473 | 0.429  | 0.192  | 0.265 | 0.321  | 0.321  | 0.321 |    0.353     |\n",
      "|     10    |  0.393   | 0.488  | 0.584  | 0.532 | 0.272  | 0.171  | 0.210 | 0.362  | 0.425  | 0.391 |    0.377     |\n",
      "|  Average  |  0.384   | 0.438  | 0.585  | 0.499 | 0.354  | 0.200  | 0.251 | 0.342  | 0.365  | 0.353 |    0.368     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mTree-based Model:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.767   | 0.862  | 0.919  | 0.890 | 0.638  | 0.878  | 0.739 | 0.902  | 0.503  | 0.646 |    0.758     |\n",
      "|     2     |  0.809   | 0.883  | 0.942  | 0.911 | 0.692  | 0.861  | 0.767 | 0.907  | 0.624  | 0.739 |    0.806     |\n",
      "|     3     |  0.863   | 0.916  | 0.920  | 0.918 | 0.760  | 0.877  | 0.814 | 0.939  | 0.791  | 0.859 |    0.864     |\n",
      "|     4     |  0.877   | 0.933  | 0.919  | 0.926 | 0.793  | 0.869  | 0.830 | 0.918  | 0.843  | 0.879 |    0.878     |\n",
      "|     5     |  0.885   | 0.924  | 0.928  | 0.926 | 0.811  | 0.858  | 0.834 | 0.927  | 0.868  | 0.897 |    0.885     |\n",
      "|     6     |  0.883   | 0.924  | 0.942  | 0.933 | 0.812  | 0.856  | 0.834 | 0.919  | 0.851  | 0.883 |    0.883     |\n",
      "|     7     |  0.808   | 0.916  | 0.941  | 0.929 | 0.671  | 0.881  | 0.762 | 0.909  | 0.600  | 0.723 |    0.805     |\n",
      "|     8     |  0.917   | 0.936  | 0.937  | 0.936 | 0.884  | 0.867  | 0.876 | 0.929  | 0.947  | 0.938 |    0.917     |\n",
      "|     9     |  0.911   | 0.933  | 0.937  | 0.935 | 0.872  | 0.865  | 0.868 | 0.928  | 0.931  | 0.930 |    0.911     |\n",
      "|     10    |  0.915   | 0.929  | 0.940  | 0.934 | 0.889  | 0.856  | 0.872 | 0.925  | 0.948  | 0.936 |    0.914     |\n",
      "|  Average  |  0.863   | 0.916  | 0.933  | 0.924 | 0.782  | 0.867  | 0.820 | 0.920  | 0.791  | 0.843 |    0.862     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mBagging-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.871   | 0.935  | 0.930  | 0.933 | 0.775  | 0.889  | 0.828 | 0.926  | 0.795  | 0.856 |    0.872     |\n",
      "|     2     |  0.907   | 0.931  | 0.947  | 0.939 | 0.859  | 0.873  | 0.866 | 0.933  | 0.903  | 0.918 |    0.907     |\n",
      "|     3     |  0.880   | 0.946  | 0.922  | 0.934 | 0.782  | 0.893  | 0.834 | 0.933  | 0.825  | 0.876 |    0.881     |\n",
      "|     4     |  0.910   | 0.938  | 0.939  | 0.938 | 0.865  | 0.869  | 0.867 | 0.928  | 0.922  | 0.925 |    0.910     |\n",
      "|     5     |  0.887   | 0.937  | 0.922  | 0.929 | 0.805  | 0.875  | 0.838 | 0.931  | 0.865  | 0.897 |    0.888     |\n",
      "|     6     |  0.893   | 0.953  | 0.941  | 0.947 | 0.822  | 0.874  | 0.847 | 0.912  | 0.865  | 0.888 |    0.894     |\n",
      "|     7     |  0.874   | 0.949  | 0.934  | 0.941 | 0.773  | 0.883  | 0.825 | 0.923  | 0.806  | 0.860 |    0.875     |\n",
      "|     8     |  0.920   | 0.945  | 0.937  | 0.941 | 0.890  | 0.869  | 0.879 | 0.925  | 0.954  | 0.939 |    0.920     |\n",
      "|     9     |  0.934   | 0.946  | 0.952  | 0.949 | 0.916  | 0.886  | 0.900 | 0.939  | 0.964  | 0.952 |    0.934     |\n",
      "|     10    |  0.936   | 0.944  | 0.961  | 0.952 | 0.926  | 0.878  | 0.902 | 0.936  | 0.968  | 0.952 |    0.935     |\n",
      "|  Average  |  0.901   | 0.942  | 0.938  | 0.940 | 0.841  | 0.879  | 0.859 | 0.929  | 0.887  | 0.906 |    0.902     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mBoosting-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.771   | 0.906  | 0.913  | 0.909 | 0.619  | 0.862  | 0.720 | 0.895  | 0.537  | 0.671 |    0.767     |\n",
      "|     2     |  0.857   | 0.901  | 0.940  | 0.920 | 0.770  | 0.854  | 0.810 | 0.918  | 0.778  | 0.842 |    0.857     |\n",
      "|     3     |  0.864   | 0.928  | 0.915  | 0.922 | 0.759  | 0.877  | 0.814 | 0.933  | 0.801  | 0.862 |    0.866     |\n",
      "|     4     |  0.852   | 0.905  | 0.931  | 0.918 | 0.768  | 0.858  | 0.811 | 0.899  | 0.767  | 0.828 |    0.852     |\n",
      "|     5     |  0.882   | 0.923  | 0.923  | 0.923 | 0.805  | 0.856  | 0.830 | 0.927  | 0.868  | 0.897 |    0.883     |\n",
      "|     6     |  0.876   | 0.918  | 0.928  | 0.923 | 0.797  | 0.857  | 0.826 | 0.921  | 0.842  | 0.880 |    0.876     |\n",
      "|     7     |  0.870   | 0.920  | 0.944  | 0.932 | 0.780  | 0.865  | 0.820 | 0.927  | 0.802  | 0.860 |    0.871     |\n",
      "|     8     |  0.884   | 0.937  | 0.928  | 0.933 | 0.815  | 0.862  | 0.837 | 0.906  | 0.863  | 0.884 |    0.885     |\n",
      "|     9     |  0.918   | 0.936  | 0.934  | 0.935 | 0.891  | 0.862  | 0.876 | 0.926  | 0.959  | 0.942 |    0.918     |\n",
      "|     10    |  0.920   | 0.931  | 0.948  | 0.940 | 0.897  | 0.861  | 0.878 | 0.930  | 0.951  | 0.940 |    0.919     |\n",
      "|  Average  |  0.869   | 0.921  | 0.930  | 0.925 | 0.790  | 0.861  | 0.822 | 0.918  | 0.817  | 0.861 |    0.869     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mDistance-based Model: \n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.665   | 0.869  | 0.899  | 0.884 | 0.505  | 0.657  | 0.571 | 0.662  | 0.440  | 0.529 |    0.661     |\n",
      "|     2     |  0.786   | 0.876  | 0.917  | 0.896 | 0.692  | 0.667  | 0.679 | 0.782  | 0.773  | 0.778 |    0.784     |\n",
      "|     3     |  0.778   | 0.876  | 0.902  | 0.889 | 0.659  | 0.700  | 0.679 | 0.806  | 0.731  | 0.766 |    0.778     |\n",
      "|     4     |  0.788   | 0.880  | 0.919  | 0.899 | 0.694  | 0.667  | 0.680 | 0.782  | 0.778  | 0.780 |    0.786     |\n",
      "|     5     |  0.768   | 0.865  | 0.886  | 0.875 | 0.657  | 0.664  | 0.661 | 0.782  | 0.754  | 0.768 |    0.768     |\n",
      "|     6     |  0.749   | 0.851  | 0.919  | 0.884 | 0.629  | 0.629  | 0.629 | 0.762  | 0.700  | 0.730 |    0.747     |\n",
      "|     7     |  0.707   | 0.875  | 0.893  | 0.884 | 0.554  | 0.682  | 0.612 | 0.727  | 0.545  | 0.623 |    0.706     |\n",
      "|     8     |  0.708   | 0.873  | 0.893  | 0.883 | 0.560  | 0.661  | 0.607 | 0.713  | 0.569  | 0.633 |    0.708     |\n",
      "|     9     |  0.680   | 0.865  | 0.900  | 0.882 | 0.518  | 0.690  | 0.592 | 0.716  | 0.451  | 0.553 |    0.676     |\n",
      "|     10    |  0.649   | 0.858  | 0.899  | 0.878 | 0.488  | 0.651  | 0.558 | 0.642  | 0.397  | 0.490 |    0.642     |\n",
      "|  Average  |  0.728   | 0.869  | 0.903  | 0.885 | 0.596  | 0.667  | 0.627 | 0.737  | 0.614  | 0.665 |    0.726     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mNaive Bayes Model: \n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.273   | 0.321  | 0.712  | 0.443 | 0.500  | 0.069  | 0.121 | 0.061  | 0.039  | 0.048 |    0.204     |\n",
      "|     2     |  0.312   | 0.334  | 0.722  | 0.457 | 0.550  | 0.084  | 0.146 | 0.187  | 0.129  | 0.152 |    0.252     |\n",
      "|     3     |  0.347   | 0.352  | 0.705  | 0.469 | 0.551  | 0.094  | 0.160 | 0.295  | 0.244  | 0.267 |    0.299     |\n",
      "|     4     |  0.366   | 0.363  | 0.721  | 0.483 | 0.597  | 0.094  | 0.162 | 0.330  | 0.283  | 0.305 |    0.317     |\n",
      "|     5     |  0.341   | 0.354  | 0.752  | 0.482 | 0.543  | 0.083  | 0.144 | 0.261  | 0.190  | 0.220 |    0.282     |\n",
      "|     6     |  0.361   | 0.365  | 0.704  | 0.481 | 0.466  | 0.083  | 0.141 | 0.330  | 0.295  | 0.311 |    0.311     |\n",
      "|     7     |  0.309   | 0.345  | 0.700  | 0.462 | 0.387  | 0.112  | 0.174 | 0.170  | 0.115  | 0.137 |    0.258     |\n",
      "|     8     |  0.383   | 0.404  | 0.767  | 0.530 | 0.347  | 0.142  | 0.201 | 0.346  | 0.241  | 0.284 |    0.338     |\n",
      "|     9     |  0.324   | 0.372  | 0.711  | 0.488 | 0.362  | 0.171  | 0.232 | 0.147  | 0.090  | 0.112 |    0.278     |\n",
      "|     10    |  0.324   | 0.413  | 0.702  | 0.520 | 0.232  | 0.144  | 0.178 | 0.186  | 0.126  | 0.150 |    0.283     |\n",
      "|  Average  |  0.334   | 0.362  | 0.720  | 0.481 | 0.454  | 0.107  | 0.166 | 0.231  | 0.175  | 0.199 |    0.282     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;0mRule-based Model: lables are only high unemployment rate(1) and not high unemployment rate(0)\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "|     id    | accuracy | precision | recall | f1 score |\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "|     1     |  0.592   |   0.720   | 0.300  |  0.423   |\n",
      "|     2     |  0.587   |   0.712   | 0.293  |  0.415   |\n",
      "|     3     |  0.617   |   0.737   | 0.365  |  0.488   |\n",
      "|     4     |  0.668   |   0.809   | 0.439  |  0.569   |\n",
      "|     5     |  0.701   |   0.814   | 0.521  |  0.636   |\n",
      "|     6     |  0.676   |   0.811   | 0.459  |  0.586   |\n",
      "|     7     |  0.678   |   0.800   | 0.474  |  0.595   |\n",
      "|     8     |  0.648   |   0.776   | 0.416  |  0.541   |\n",
      "|     9     |  0.645   |   0.778   | 0.406  |  0.533   |\n",
      "|     10    |  0.654   |   0.790   | 0.419  |  0.548   |\n",
      "|  Average  |  0.647   |   0.775   | 0.409  |  0.533   |\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "Instances are often misclassified:  41\n",
      "\u001b[1mAfter Balanced Sampling: ---------------------------------------------------------------------------\n",
      "\u001b[0;0mLinear-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.530   | 0.508  | 0.815  | 0.626 | 0.810  | 0.073  | 0.134 | 0.550  | 0.518  | 0.534 |    0.431     |\n",
      "|     2     |  0.537   | 0.521  | 0.670  | 0.586 | 0.821  | 0.074  | 0.136 | 0.541  | 0.681  | 0.603 |    0.442     |\n",
      "|     3     |  0.549   | 0.520  | 0.733  | 0.609 | 0.739  | 0.128  | 0.218 | 0.568  | 0.616  | 0.591 |    0.472     |\n",
      "|     4     |  0.420   | 0.404  | 0.419  | 0.411 | 0.366  | 0.108  | 0.167 | 0.439  | 0.608  | 0.510 |    0.363     |\n",
      "|     5     |  0.426   | 0.432  | 0.445  | 0.438 | 0.600  | 0.048  | 0.089 | 0.416  | 0.633  | 0.502 |    0.343     |\n",
      "|     6     |  0.393   | 0.338  | 0.333  | 0.335 | 0.831  | 0.069  | 0.127 | 0.413  | 0.647  | 0.504 |    0.322     |\n",
      "|     7     |  0.502   | 0.523  | 0.650  | 0.580 | 0.266  | 0.105  | 0.151 | 0.529  | 0.592  | 0.559 |    0.430     |\n",
      "|     8     |  0.524   | 0.561  | 0.641  | 0.598 | 0.581  | 0.100  | 0.170 | 0.489  | 0.662  | 0.562 |    0.444     |\n",
      "|     9     |  0.479   | 0.490  | 0.711  | 0.580 | 0.062  | 0.013  | 0.021 | 0.513  | 0.525  | 0.519 |    0.374     |\n",
      "|     10    |  0.489   | 0.511  | 0.623  | 0.562 | 0.173  | 0.030  | 0.051 | 0.494  | 0.630  | 0.554 |    0.389     |\n",
      "|  Average  |  0.485   | 0.481  | 0.604  | 0.533 | 0.525  | 0.075  | 0.126 | 0.495  | 0.611  | 0.544 |    0.401     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mLinear-based Model 2:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.515   | 0.484  | 0.852  | 0.617 | 0.907  | 0.073  | 0.135 | 0.561  | 0.443  | 0.495 |    0.416     |\n",
      "|     2     |  0.545   | 0.521  | 0.704  | 0.599 | 0.722  | 0.070  | 0.127 | 0.564  | 0.671  | 0.613 |    0.446     |\n",
      "|     3     |  0.537   | 0.529  | 0.677  | 0.594 | 0.503  | 0.084  | 0.143 | 0.548  | 0.669  | 0.602 |    0.447     |\n",
      "|     4     |  0.428   | 0.411  | 0.493  | 0.448 | 0.701  | 0.073  | 0.132 | 0.431  | 0.577  | 0.493 |    0.358     |\n",
      "|     5     |  0.461   | 0.456  | 0.514  | 0.484 | 0.483  | 0.061  | 0.109 | 0.463  | 0.647  | 0.540 |    0.377     |\n",
      "|     6     |  0.462   | 0.440  | 0.502  | 0.469 | 0.633  | 0.067  | 0.120 | 0.473  | 0.660  | 0.551 |    0.380     |\n",
      "|     7     |  0.511   | 0.502  | 0.606  | 0.549 | 0.789  | 0.076  | 0.139 | 0.507  | 0.677  | 0.580 |    0.423     |\n",
      "|     8     |  0.525   | 0.550  | 0.671  | 0.604 | 0.744  | 0.065  | 0.120 | 0.494  | 0.655  | 0.563 |    0.429     |\n",
      "|     9     |  0.503   | 0.533  | 0.642  | 0.583 | 0.000  | 0.000  | 0.000 | 0.488  | 0.666  | 0.563 |    0.382     |\n",
      "|     10    |  0.502   | 0.528  | 0.671  | 0.591 | 0.000  | 0.000  | 0.000 | 0.493  | 0.634  | 0.555 |    0.382     |\n",
      "|  Average  |  0.499   | 0.495  | 0.633  | 0.554 | 0.548  | 0.057  | 0.103 | 0.502  | 0.630  | 0.556 |    0.404     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mTree-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.901   | 0.863  | 0.992  | 0.923 | 0.944  | 0.630  | 0.756 | 0.927  | 0.973  | 0.949 |    0.876     |\n",
      "|     2     |  0.937   | 0.952  | 0.979  | 0.965 | 0.922  | 0.806  | 0.860 | 0.931  | 0.975  | 0.953 |    0.926     |\n",
      "|     3     |  0.952   | 0.948  | 0.990  | 0.969 | 0.939  | 0.846  | 0.890 | 0.963  | 0.977  | 0.970 |    0.943     |\n",
      "|     4     |  0.927   | 0.987  | 0.858  | 0.918 | 0.794  | 0.927  | 0.855 | 0.966  | 0.995  | 0.980 |    0.918     |\n",
      "|     5     |  0.944   | 0.953  | 0.936  | 0.945 | 0.880  | 0.882  | 0.881 | 0.972  | 0.988  | 0.980 |    0.935     |\n",
      "|     6     |  0.974   | 0.960  | 0.998  | 0.979 | 0.986  | 0.906  | 0.944 | 0.982  | 0.992  | 0.987 |    0.970     |\n",
      "|     7     |  0.968   | 0.957  | 0.993  | 0.975 | 0.973  | 0.885  | 0.927 | 0.975  | 0.992  | 0.983 |    0.962     |\n",
      "|     8     |  0.955   | 0.937  | 0.984  | 0.960 | 0.962  | 0.844  | 0.899 | 0.970  | 0.993  | 0.982 |    0.947     |\n",
      "|     9     |  0.977   | 0.982  | 0.988  | 0.985 | 0.973  | 0.936  | 0.954 | 0.974  | 0.991  | 0.982 |    0.974     |\n",
      "|     10    |  0.974   | 0.993  | 0.986  | 0.989 | 0.967  | 0.932  | 0.949 | 0.961  | 0.988  | 0.974 |    0.971     |\n",
      "|  Average  |  0.951   | 0.953  | 0.970  | 0.961 | 0.934  | 0.859  | 0.892 | 0.962  | 0.986  | 0.974 |    0.942     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mBagging-based Model:\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.945   | 0.934  | 0.990  | 0.961 | 0.975  | 0.793  | 0.875 | 0.943  | 0.992  | 0.967 |    0.934     |\n",
      "|     2     |  0.945   | 0.954  | 0.969  | 0.961 | 0.935  | 0.831  | 0.880 | 0.942  | 0.990  | 0.966 |    0.936     |\n",
      "|     3     |  0.957   | 0.940  | 0.994  | 0.966 | 0.968  | 0.848  | 0.904 | 0.969  | 0.986  | 0.978 |    0.949     |\n",
      "|     4     |  0.943   | 0.991  | 0.904  | 0.945 | 0.850  | 0.920  | 0.883 | 0.958  | 0.995  | 0.977 |    0.935     |\n",
      "|     5     |  0.955   | 0.951  | 0.967  | 0.959 | 0.933  | 0.871  | 0.901 | 0.970  | 0.993  | 0.981 |    0.947     |\n",
      "|     6     |  0.970   | 0.963  | 0.999  | 0.981 | 0.986  | 0.882  | 0.931 | 0.967  | 0.993  | 0.980 |    0.964     |\n",
      "|     7     |  0.974   | 0.970  | 0.987  | 0.978 | 0.969  | 0.920  | 0.944 | 0.979  | 0.993  | 0.986 |    0.969     |\n",
      "|     8     |  0.959   | 0.963  | 0.988  | 0.976 | 0.973  | 0.852  | 0.908 | 0.948  | 0.994  | 0.971 |    0.952     |\n",
      "|     9     |  0.983   | 0.992  | 0.992  | 0.992 | 0.982  | 0.952  | 0.967 | 0.975  | 0.994  | 0.984 |    0.981     |\n",
      "|     10    |  0.989   | 0.997  | 0.991  | 0.994 | 0.976  | 0.984  | 0.980 | 0.990  | 0.990  | 0.990 |    0.988     |\n",
      "|  Average  |  0.962   | 0.966  | 0.978  | 0.971 | 0.955  | 0.885  | 0.917 | 0.964  | 0.992  | 0.978 |    0.956     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mBoosting-based Model:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.947   | 0.953  | 0.982  | 0.967 | 0.937  | 0.845  | 0.888 | 0.947  | 0.974  | 0.961 |    0.939     |\n",
      "|     2     |  0.937   | 0.955  | 0.963  | 0.959 | 0.899  | 0.837  | 0.867 | 0.941  | 0.972  | 0.957 |    0.927     |\n",
      "|     3     |  0.946   | 0.950  | 0.981  | 0.965 | 0.912  | 0.857  | 0.884 | 0.962  | 0.965  | 0.963 |    0.937     |\n",
      "|     4     |  0.936   | 0.987  | 0.889  | 0.935 | 0.833  | 0.914  | 0.872 | 0.957  | 0.997  | 0.977 |    0.928     |\n",
      "|     5     |  0.934   | 0.947  | 0.914  | 0.930 | 0.851  | 0.879  | 0.865 | 0.972  | 0.987  | 0.979 |    0.925     |\n",
      "|     6     |  0.960   | 0.964  | 0.998  | 0.981 | 0.991  | 0.836  | 0.907 | 0.942  | 0.997  | 0.968 |    0.952     |\n",
      "|     7     |  0.967   | 0.960  | 0.986  | 0.973 | 0.964  | 0.897  | 0.929 | 0.975  | 0.990  | 0.982 |    0.962     |\n",
      "|     8     |  0.941   | 0.950  | 0.985  | 0.967 | 0.968  | 0.784  | 0.867 | 0.919  | 0.990  | 0.954 |    0.929     |\n",
      "|     9     |  0.969   | 0.978  | 0.988  | 0.983 | 0.977  | 0.898  | 0.936 | 0.956  | 0.992  | 0.974 |    0.964     |\n",
      "|     10    |  0.980   | 0.990  | 0.983  | 0.986 | 0.962  | 0.974  | 0.968 | 0.981  | 0.980  | 0.981 |    0.978     |\n",
      "|  Average  |  0.952   | 0.963  | 0.967  | 0.965 | 0.929  | 0.872  | 0.898 | 0.955  | 0.984  | 0.970 |    0.944     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mDistance-based Model: \n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.886   | 0.878  | 0.997  | 0.934 | 0.984  | 0.520  | 0.680 | 0.867  | 0.995  | 0.927 |    0.847     |\n",
      "|     2     |  0.924   | 0.958  | 0.984  | 0.971 | 0.971  | 0.705  | 0.817 | 0.876  | 0.995  | 0.932 |    0.906     |\n",
      "|     3     |  0.928   | 0.937  | 0.989  | 0.962 | 0.970  | 0.719  | 0.826 | 0.902  | 0.992  | 0.945 |    0.911     |\n",
      "|     4     |  0.941   | 0.972  | 0.970  | 0.971 | 0.950  | 0.802  | 0.870 | 0.908  | 0.995  | 0.950 |    0.930     |\n",
      "|     5     |  0.932   | 0.957  | 0.967  | 0.962 | 0.919  | 0.780  | 0.844 | 0.914  | 0.988  | 0.950 |    0.918     |\n",
      "|     6     |  0.932   | 0.953  | 0.973  | 0.963 | 0.938  | 0.774  | 0.848 | 0.910  | 0.986  | 0.947 |    0.919     |\n",
      "|     7     |  0.930   | 0.951  | 0.969  | 0.960 | 0.934  | 0.773  | 0.846 | 0.908  | 0.986  | 0.945 |    0.917     |\n",
      "|     8     |  0.897   | 0.903  | 0.983  | 0.941 | 0.951  | 0.603  | 0.738 | 0.874  | 0.988  | 0.928 |    0.869     |\n",
      "|     9     |  0.857   | 0.870  | 0.981  | 0.922 | 0.901  | 0.438  | 0.589 | 0.834  | 0.983  | 0.902 |    0.804     |\n",
      "|     10    |  0.835   | 0.828  | 0.979  | 0.897 | 0.890  | 0.349  | 0.501 | 0.831  | 0.983  | 0.901 |    0.766     |\n",
      "|  Average  |  0.906   | 0.921  | 0.979  | 0.948 | 0.941  | 0.646  | 0.756 | 0.882  | 0.989  | 0.933 |    0.879     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mNaive Bayes Model: \n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     id    | accuracy | pre[h] | rec[h] | f1[h] | pre[m] | rec[m] | f1[m] | pre[l] | rec[l] | f1[l] | f[avg_macro] |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "|     1     |  0.489   | 0.449  | 0.948  | 0.610 | 0.792  | 0.126  | 0.218 | 0.627  | 0.246  | 0.353 |    0.394     |\n",
      "|     2     |  0.533   | 0.474  | 0.837  | 0.605 | 0.681  | 0.165  | 0.266 | 0.653  | 0.450  | 0.533 |    0.468     |\n",
      "|     3     |  0.498   | 0.459  | 0.767  | 0.575 | 0.656  | 0.153  | 0.248 | 0.552  | 0.436  | 0.487 |    0.437     |\n",
      "|     4     |  0.374   | 0.371  | 0.548  | 0.443 | 0.610  | 0.131  | 0.215 | 0.348  | 0.346  | 0.347 |    0.335     |\n",
      "|     5     |  0.473   | 0.432  | 0.639  | 0.515 | 0.584  | 0.101  | 0.172 | 0.521  | 0.529  | 0.525 |    0.404     |\n",
      "|     6     |  0.192   | 0.000  | 0.000  | 0.000 | 0.449  | 0.127  | 0.197 | 0.295  | 0.423  | 0.348 |    0.182     |\n",
      "|     7     |  0.413   | 0.355  | 0.516  | 0.421 | 0.583  | 0.129  | 0.211 | 0.475  | 0.481  | 0.478 |    0.370     |\n",
      "|     8     |  0.503   | 0.480  | 0.737  | 0.581 | 0.570  | 0.092  | 0.159 | 0.533  | 0.515  | 0.524 |    0.421     |\n",
      "|     9     |  0.504   | 0.546  | 0.721  | 0.622 | 0.390  | 0.049  | 0.088 | 0.464  | 0.558  | 0.507 |    0.405     |\n",
      "|     10    |  0.490   | 0.540  | 0.754  | 0.629 | 0.364  | 0.050  | 0.089 | 0.436  | 0.489  | 0.461 |    0.393     |\n",
      "|  Average  |  0.447   | 0.411  | 0.647  | 0.500 | 0.568  | 0.112  | 0.186 | 0.490  | 0.447  | 0.456 |    0.381     |\n",
      "+-----------+----------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------------+\n",
      "\u001b[0;0mRule-based Model: lables are only high unemployment rate(1) and not high unemployment rate(0)\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "|     id    | accuracy | precision | recall | f1 score |\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "|     1     |  0.583   |   0.797   | 0.258  |  0.390   |\n",
      "|     2     |  0.667   |   0.867   | 0.420  |  0.565   |\n",
      "|     3     |  0.680   |   0.875   | 0.445  |  0.590   |\n",
      "|     4     |  0.641   |   0.811   | 0.399  |  0.535   |\n",
      "|     5     |  0.683   |   0.896   | 0.438  |  0.588   |\n",
      "|     6     |  0.675   |   0.874   | 0.434  |  0.580   |\n",
      "|     7     |  0.659   |   0.800   | 0.454  |  0.579   |\n",
      "|     8     |  0.669   |   0.832   | 0.451  |  0.585   |\n",
      "|     9     |  0.672   |   0.842   | 0.449  |  0.586   |\n",
      "|     10    |  0.670   |   0.842   | 0.445  |  0.583   |\n",
      "|  Average  |  0.660   |   0.844   | 0.419  |  0.558   |\n",
      "+-----------+----------+-----------+--------+----------+\n",
      "Instances are often misclassified:  12\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from skrules import SkopeRules\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from prettytable import PrettyTable\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "def cv_train_test_split(X, y):\n",
    "    X_Train, Y_Train, X_Test, Y_Test = [], [], [], []\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            X_Train.append(X_train)\n",
    "            X_Test.append(X_test)\n",
    "            Y_Train.append(y_train)\n",
    "            Y_Test.append(y_test)\n",
    "    return X_Train, Y_Train, X_Test, Y_Test\n",
    "\n",
    "feature_train_over, label_train_over, feature_test_over, label_test_over = cv_train_test_split(X_over, y_over)\n",
    "feature_train_ru_over, label_train_ru_over, feature_test_ru_over, label_test_ru_over = cv_train_test_split(X_over_rule, y_over_rule)\n",
    "\n",
    "feature_train_und, label_train_und, feature_test_und, label_test_und = cv_train_test_split(X_und, y_und)\n",
    "feature_train_ru_und, label_train_ru_und, feature_test_ru_und, label_test_ru_und = cv_train_test_split(X_und_rule, y_und_rule)\n",
    "\n",
    "feature_train_bal, label_train_bal, feature_test_bal, label_test_bal = cv_train_test_split(X_bal, y_bal)\n",
    "feature_train_ru_bal, label_train_ru_bal, feature_test_ru_bal, label_test_ru_bal = cv_train_test_split(X_bal_rule, y_bal_rule)\n",
    "\n",
    "def model(m, feature_train, label_train, feature_test, label_test, X, y):\n",
    "    if m == \"linear\":\n",
    "        warnings.filterwarnings('ignore')\n",
    "        lin_cla  = linear_model.SGDClassifier(loss='modified_huber') # default: ‘hinge’\n",
    "        print(reset + \"Linear-based Model:\")\n",
    "        printScore(lin_cla, feature_train, label_train, feature_test, label_test)\n",
    "        cla_wrong(lin_cla, X, y)\n",
    "    if m == \"linear1\":\n",
    "        warnings.filterwarnings('ignore')\n",
    "        lin_cla1  = OneVsRestClassifier(LinearSVC(random_state=0, multi_class='ovr'))\n",
    "        # We use the linear support vecotr classification LinearSVC with the OneVsRestClassifier wrapper\n",
    "        # OneVsRestClassifier is a multiclass strategy. \n",
    "        # We set the LinearSVC's multi class as \"ovr\" (multi-class strategy)\n",
    "        #\"ovr\" trains n classes one-vs-rest classifiers \n",
    "        print(reset + \"Linear-based Model 2:\")\n",
    "        printScore(lin_cla1, feature_train, label_train, feature_test, label_test)\n",
    "        cla_wrong(lin_cla1, X, y)\n",
    "    elif m == \"tree\":\n",
    "        tree_cla = tree.DecisionTreeClassifier(criterion = \"entropy\") # default: gini\n",
    "        print(reset + \"Tree-based Model:\")\n",
    "        printScore(tree_cla, feature_train, label_train, feature_test, label_test)\n",
    "        cla_wrong(tree_cla, X, y)\n",
    "    elif m == \"bagging\": \n",
    "        bagging_cla = BaggingClassifier() # decision tree is the base estimator\n",
    "        print(reset + \"Bagging-based Model:\")\n",
    "        printScore(bagging_cla, feature_train, label_train, feature_test, label_test)\n",
    "        cla_wrong(bagging_cla, X, y)\n",
    "    elif m == \"boosting\":\n",
    "        boosting_cla = AdaBoostClassifier(tree.DecisionTreeClassifier(), n_estimators=100, random_state=0)\n",
    "        # default: 50, the maximum number of estimators at which boosting is terminated.\n",
    "        print(reset + \"Boosting-based Model:\")\n",
    "        printScore(boosting_cla, feature_train, label_train, feature_test, label_test)\n",
    "        cla_wrong(boosting_cla, X, y)\n",
    "    elif m == \"neighbors\":\n",
    "        neigh_cla = KNeighborsClassifier(n_neighbors=5, p=5)\n",
    "        #tried 3 and 5, 5 is better. \n",
    "        #p: default 2(Euclidean distance); 5: minkowski distance; 1, manhattan distance \n",
    "        print(reset + \"Distance-based Model: \")\n",
    "        printScore(neigh_cla, feature_train, label_train, feature_test, label_test)\n",
    "        cla_wrong(neigh_cla, X, y)\n",
    "    elif m == \"bayes\":\n",
    "        nb_cla = GaussianNB() \n",
    "        print(reset + \"Naive Bayes Model: \")\n",
    "        printScore(nb_cla, feature_train, label_train, feature_test, label_test)\n",
    "        cla_wrong(nb_cla, X, y)\n",
    "    elif m == \"rule\":\n",
    "        warnings.filterwarnings('ignore')\n",
    "        rb_cla = SkopeRules(max_depth_duplication=3,\n",
    "                 n_estimators=30,\n",
    "                 precision_min=0.6,\n",
    "                 recall_min=0.01)\n",
    "        print(reset + \"Rule-based Model: lables are only high unemployment rate(1) and not high unemployment rate(0)\")\n",
    "        printScore_rule(rb_cla, feature_train, label_train, feature_test, label_test)\n",
    "        \n",
    "def printScore(model, feature_train, label_train, feature_test, label_test):\n",
    "        t = PrettyTable(['id', 'accuracy', 'pre[h]', 'rec[h]', 'f1[h]', 'pre[m]', 'rec[m]', 'f1[m]',\n",
    "                        'pre[l]', 'rec[l]', 'f1[l]', 'f[avg_macro]'])\n",
    "        sum_acc, sum_pre, sum_rec, sum_f, sum_pre2, sum_rec2, sum_f2, sum_pre1, sum_rec1, sum_f1, sum_f_total = 0,0,0,0,0,0,0,0,0,0,0\n",
    "        for i in range(10):\n",
    "            model.fit(feature_train[i], label_train[i])\n",
    "            y_pred = model.predict(feature_test[i])\n",
    "            acc = accuracy_score(label_test[i], y_pred)\n",
    "            pre = precision_score(label_test[i], y_pred, average = None, labels = [2])\n",
    "            rec = recall_score(label_test[i], y_pred, average = None, labels = [2])\n",
    "            f_score = f1_score(label_test[i], y_pred, average = None, labels = [2])\n",
    "            pre2 = precision_score(label_test[i], y_pred, average = None, labels = [1])\n",
    "            rec2 = recall_score(label_test[i], y_pred, average = None, labels = [1])\n",
    "            f_score2 = f1_score(label_test[i], y_pred, average = None, labels = [1])\n",
    "            pre1 = precision_score(label_test[i], y_pred, average = None, labels = [0])\n",
    "            rec1 = recall_score(label_test[i], y_pred, average = None, labels = [0])\n",
    "            f_score1 = f1_score(label_test[i], y_pred, average = None, labels = [0])\n",
    "            f_score_total = f1_score(label_test[i], y_pred, average = \"macro\")\n",
    "            t.add_row([i+1, '{0:.3f}'.format(float(acc)), '{0:.3f}'.format(float(pre)), '{0:.3f}'.format(float(rec)),\n",
    "                      '{0:.3f}'.format(float(f_score)), '{0:.3f}'.format(float(pre2)), '{0:.3f}'.format(float(rec2)),\n",
    "                      '{0:.3f}'.format(float(f_score2)),\n",
    "                      '{0:.3f}'.format(float(pre1)), '{0:.3f}'.format(float(rec1)),\n",
    "                      '{0:.3f}'.format(float(f_score1)),'{0:.3f}'.format(float(f_score_total))])\n",
    "            sum_acc += float(acc)\n",
    "            sum_pre += float(pre)\n",
    "            sum_rec += float(rec)\n",
    "            sum_f += float(f_score)\n",
    "            sum_pre2 += float(pre2)\n",
    "            sum_rec2 += float(rec2)\n",
    "            sum_f2 += float(f_score2)\n",
    "            sum_pre1 += float(pre1)\n",
    "            sum_rec1 += float(rec1)\n",
    "            sum_f1 += float(f_score1)\n",
    "            sum_f_total += float(f_score_total)\n",
    "        avg_acc = sum_acc/10\n",
    "        avg_pre = sum_pre/10\n",
    "        avg_rec = sum_rec/10\n",
    "        avg_f = sum_f/10\n",
    "        avg_pre2 = sum_pre2/10\n",
    "        avg_rec2 = sum_rec2/10\n",
    "        avg_f2 = sum_f2/10\n",
    "        avg_pre1 = sum_pre1/10\n",
    "        avg_rec1 = sum_rec1/10\n",
    "        avg_f1 = sum_f1/10\n",
    "        avg_f_total = sum_f_total/10\n",
    "        t.add_row([\" Average \", '{0:.3f}'.format(avg_acc), '{0:.3f}'.format(avg_pre), '{0:.3f}'.format(avg_rec),\n",
    "                  '{0:.3f}'.format(avg_f),'{0:.3f}'.format(avg_pre2), '{0:.3f}'.format(avg_rec2),\n",
    "                  '{0:.3f}'.format(avg_f2), '{0:.3f}'.format(avg_pre1), '{0:.3f}'.format(avg_rec1),\n",
    "                  '{0:.3f}'.format(avg_f1), '{0:.3f}'.format(avg_f_total)])\n",
    "        print(t)\n",
    "        \n",
    "\n",
    "def printScore_rule(model, feature_train, label_train, feature_test, label_test):\n",
    "        t = PrettyTable(['id', 'accuracy', 'precision', 'recall', 'f1 score'])\n",
    "        sum_acc, sum_pre, sum_rec, sum_f= 0,0,0,0\n",
    "        for i in range(10):\n",
    "            model.fit(feature_train[i], label_train[i])\n",
    "            y_pred = model.predict(feature_test[i])\n",
    "            acc = accuracy_score(label_test[i], y_pred)\n",
    "            pre = precision_score(label_test[i], y_pred, average = 'binary')\n",
    "            rec = recall_score(label_test[i], y_pred, average = 'binary')\n",
    "            f_score = f1_score(label_test[i], y_pred, average = 'binary')\n",
    "            # Only report results for the class specified by pos_label\n",
    "            t.add_row([i+1, '{0:.3f}'.format(acc), '{0:.3f}'.format(pre), '{0:.3f}'.format(rec),\n",
    "                      '{0:.3f}'.format(f_score)])\n",
    "            sum_acc += float(acc)\n",
    "            sum_pre += float(pre)\n",
    "            sum_rec += float(rec)\n",
    "            sum_f += float(f_score)\n",
    "        avg_acc = sum_acc/10\n",
    "        avg_pre = sum_pre/10\n",
    "        avg_rec = sum_rec/10\n",
    "        avg_f = sum_f/10\n",
    "        t.add_row([\" Average \", '{0:.3f}'.format(avg_acc), '{0:.3f}'.format(avg_pre), '{0:.3f}'.format(avg_rec),\n",
    "                  '{0:.3f}'.format(avg_f)])\n",
    "        print(t)\n",
    "\n",
    "        \n",
    "X_dic = dict()\n",
    "def cla_wrong(model, f_data, l_data):\n",
    "        y_pred = model.predict(f_data)\n",
    "        for i in range(len(l_data)):\n",
    "            if l_data[i]!=y_pred[i]:\n",
    "                if i in dict.keys(X_dic):\n",
    "                    X_dic[i] +=1\n",
    "                else:\n",
    "                    X_dic[i] =1\n",
    "\n",
    "def cla_often_wrong(X_dic, X, y, sample):\n",
    "    X_wrong, Y_wrong = [], []\n",
    "    X_dic = {key: value for (key, value) in X_dic.items() if value == 7 }\n",
    "    for key in X_dic.keys():\n",
    "        X_wrong.append(X[key])\n",
    "        Y_wrong.append(y[key])\n",
    "    data_wrong = pd.DataFrame(X_wrong)\n",
    "    data_wrong[\"Unemployment Rate\"] = pd.DataFrame(Y_wrong)\n",
    "    feature_dict = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        feature_dict[i] = feature_names[i]\n",
    "    data_wrong = data_wrong.rename(columns=feature_dict)\n",
    "#   print(data_wrong.head())\n",
    "    print(\"Instances are often misclassified: \", len(X_dic))\n",
    "    \n",
    "    if sample == \"over\":\n",
    "        data_wrong.to_excel(\"Oversampling_misclassified.xlsx\")  \n",
    "        \n",
    "    elif sample == \"und\":\n",
    "        data_wrong.to_excel(\"Undersampling_misclassified.xlsx\")  \n",
    "            \n",
    "    if sample == \"bal\":\n",
    "        data_wrong.to_excel(\"Balancedsampling_misclassified.xlsx\")  \n",
    "        \n",
    "bold = \"\\033[1m\" \n",
    "reset = \"\\033[0;0m\"\n",
    "print(bold + \"After Over Sampling: ---------------------------------------------------------------------------\")\n",
    "model(\"linear\", feature_train_over, label_train_over, feature_test_over, label_test_over, X_over, y_over)\n",
    "model(\"linear1\", feature_train_over, label_train_over, feature_test_over, label_test_over, X_over, y_over)\n",
    "model(\"tree\", feature_train_over, label_train_over, feature_test_over, label_test_over, X_over, y_over)\n",
    "model(\"bagging\", feature_train_over, label_train_over, feature_test_over, label_test_over, X_over, y_over)\n",
    "model(\"boosting\", feature_train_over, label_train_over, feature_test_over, label_test_over, X_over, y_over)\n",
    "model(\"neighbors\", feature_train_over, label_train_over, feature_test_over, label_test_over, X_over, y_over)\n",
    "model(\"bayes\", feature_train_over, label_train_over, feature_test_over, label_test_over, X_over, y_over)\n",
    "model(\"rule\", feature_train_ru_over, label_train_ru_over, feature_test_ru_over, label_test_ru_over, X_over_rule, y_over_rule)\n",
    "cla_often_wrong(X_dic, X_over, y_over, \"over\")\n",
    "\n",
    "X_dic = dict()\n",
    "print(bold + \"After Under Sampling: ---------------------------------------------------------------------------\")\n",
    "model(\"linear\", feature_train_und, label_train_und, feature_test_und, label_test_und, X_und, y_und)\n",
    "model(\"linear1\", feature_train_und, label_train_und, feature_test_und, label_test_und, X_und, y_und)\n",
    "model(\"tree\", feature_train_und, label_train_und, feature_test_und, label_test_und, X_und, y_und)\n",
    "model(\"bagging\", feature_train_und, label_train_und, feature_test_und, label_test_und, X_und, y_und)\n",
    "model(\"boosting\", feature_train_und, label_train_und, feature_test_und, label_test_und, X_und, y_und)\n",
    "model(\"neighbors\", feature_train_und, label_train_und, feature_test_und, label_test_und, X_und, y_und)\n",
    "model(\"bayes\", feature_train_und, label_train_und, feature_test_und, label_test_und, X_und, y_und)\n",
    "model(\"rule\", feature_train_ru_und, label_train_ru_und, feature_test_ru_und, label_test_ru_und, X_und_rule, y_und_rule)\n",
    "cla_often_wrong(X_dic, X_und, y_und, \"und\")\n",
    "\n",
    "\n",
    "X_dic = dict()\n",
    "print(bold + \"After Balanced Sampling: ---------------------------------------------------------------------------\")\n",
    "model(\"linear\", feature_train_bal, label_train_bal, feature_test_bal, label_test_bal, X_bal, y_bal)\n",
    "model(\"linear1\", feature_train_bal, label_train_bal, feature_test_bal, label_test_bal, X_bal, y_bal)\n",
    "model(\"tree\", feature_train_bal, label_train_bal, feature_test_bal, label_test_bal, X_bal, y_bal)\n",
    "model(\"bagging\", feature_train_bal, label_train_bal, feature_test_bal, label_test_bal, X_bal, y_bal)\n",
    "model(\"boosting\", feature_train_bal, label_train_bal, feature_test_bal, label_test_bal, X_bal, y_bal)\n",
    "model(\"neighbors\", feature_train_bal, label_train_bal, feature_test_bal, label_test_bal, X_bal, y_bal)\n",
    "model(\"bayes\", feature_train_bal, label_train_bal, feature_test_bal, label_test_bal, X_bal, y_bal)\n",
    "model(\"rule\", feature_train_ru_bal, label_train_ru_bal, feature_test_ru_bal, label_test_ru_bal, X_bal_rule, y_bal_rule)\n",
    "cla_often_wrong(X_dic, X_bal, y_bal, \"bal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
